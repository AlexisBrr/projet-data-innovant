{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Jupyter adapté pour le nettoyage et la transformation des jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Jeu de données ghostbikes (accident mortel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un fichier .geojson\n",
    "def load_geojson(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Fonction pour nettoyer les données\n",
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for feature in data.get(\"features\", []):\n",
    "        properties = feature.get(\"properties\", {})\n",
    "        geometry = feature.get(\"geometry\", {})\n",
    "        coordinates = geometry.get(\"coordinates\", [])\n",
    "        if len(coordinates) == 2:\n",
    "            cleaned_data.append({\n",
    "                \"id\": properties.get(\"@id\"),\n",
    "                \"lat\": coordinates[1],\n",
    "                \"lon\": coordinates[0],\n",
    "                \"start_date\": properties.get(\"start_date\")\n",
    "            })\n",
    "    return cleaned_data\n",
    "\n",
    "# Fonction pour écrire les données nettoyées dans un fichier CSV\n",
    "def write_to_csv(cleaned_data, output_file):\n",
    "    with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"id\", \"lat\", \"lon\", \"start_date\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(cleaned_data)\n",
    "\n",
    "# Chemin d'entrée et de sortie\n",
    "input_file = \"export.geojson\"\n",
    "output_file = \"ghostbikes.csv\"\n",
    "\n",
    "# Chargement, nettoyage et exportation\n",
    "data = load_geojson(input_file)\n",
    "cleaned_data = clean_data(data)\n",
    "write_to_csv(cleaned_data, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Finalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id        lat       lon  start_date statut_accident\n",
      "0   9611135117  45.180153  5.716451  2022-03-26          Mortel\n",
      "1  11002892805  45.177253  5.718046  2023-06-24          Mortel\n"
     ]
    }
   ],
   "source": [
    "data_ghostbike = pd.read_csv(\"ghostbikes.csv\", sep=\",\")\n",
    "filtered_filtered_filtered_df_ghostbike = pd.DataFrame(data_ghostbike)\n",
    "# Suppression de \"node/\" dans la colonne 'id'\n",
    "df_ghostbike[\"id\"] = df_ghostbike[\"id\"].str.replace(\"node/\", \"\")\n",
    "# Ajout de la colonne 'statut_accident' avec la valeur \"Mortel\"\n",
    "df_ghostbike[\"statut_accident\"] = \"Mortel\"\n",
    "print(df_ghostbike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Jeu de données accident de vélo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtrage pour la commune de Grenoble (Code INSEE : 38185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74758 entries, 0 to 74757\n",
      "Data columns (total 39 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Num_Acc          74758 non-null  int64  \n",
      " 1   date             74758 non-null  object \n",
      " 2   an               74758 non-null  int64  \n",
      " 3   mois             74758 non-null  object \n",
      " 4   jour             74758 non-null  object \n",
      " 5   hrmn             74758 non-null  object \n",
      " 6   dep              74758 non-null  object \n",
      " 7   com              74758 non-null  object \n",
      " 8   lat              74758 non-null  object \n",
      " 9   long             74490 non-null  object \n",
      " 10  agg              74758 non-null  int64  \n",
      " 11  int              74758 non-null  int64  \n",
      " 12  col              74754 non-null  float64\n",
      " 13  lum              74758 non-null  int64  \n",
      " 14  atm              74755 non-null  float64\n",
      " 15  catr             74758 non-null  int64  \n",
      " 16  circ             74615 non-null  float64\n",
      " 17  nbv              74561 non-null  float64\n",
      " 18  prof             74581 non-null  float64\n",
      " 19  plan             74558 non-null  float64\n",
      " 20  lartpc           63786 non-null  object \n",
      " 21  larrout          69666 non-null  object \n",
      " 22  surf             74584 non-null  float64\n",
      " 23  infra            74222 non-null  float64\n",
      " 24  situ             74264 non-null  float64\n",
      " 25  grav             74758 non-null  int64  \n",
      " 26  sexe             74758 non-null  int64  \n",
      " 27  age              74732 non-null  float64\n",
      " 28  trajet           74755 non-null  float64\n",
      " 29  secuexist        74758 non-null  int64  \n",
      " 30  equipement       71017 non-null  object \n",
      " 31  obs              74732 non-null  float64\n",
      " 32  obsm             74717 non-null  float64\n",
      " 33  choc             74746 non-null  float64\n",
      " 34  manv             74742 non-null  float64\n",
      " 35  vehiculeid       74758 non-null  object \n",
      " 36  typevehicules    64465 non-null  object \n",
      " 37  manoeuvehicules  64448 non-null  object \n",
      " 38  numVehicules     64465 non-null  float64\n",
      "dtypes: float64(16), int64(9), object(14)\n",
      "memory usage: 22.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\3616175776.py:1: DtypeWarning: Columns (8,9,20,21,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_accident_velo = pd.read_csv(\"accidentsVelo.csv\", sep=\",\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(337, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accident_velo = pd.read_csv(\"accidentsVelo.csv\", sep=\",\")\n",
    "df_accident_velo = pd.DataFrame(data_accident_velo)\n",
    "df_accident_velo.info()\n",
    "\n",
    "# Filtrer les données selon le code INSEE de la commune de grenoble (38185)\n",
    "filtered_df = df_accident_velo[(df_accident_velo[\"com\"] == \"38185\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\3496815627.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"lat\"] = filtered_df[\"lat\"].astype(str).str.replace(\",\", \".\")\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\3496815627.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"long\"] = filtered_df[\"long\"].astype(str).str.replace(\",\", \".\")\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\3496815627.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"lat\"] = filtered_df[\"lat\"].astype(float)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\3496815627.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"long\"] = filtered_df[\"long\"].astype(float)\n"
     ]
    }
   ],
   "source": [
    "filtered_df[\"lat\"] = filtered_df[\"lat\"].astype(str).str.replace(\",\", \".\")\n",
    "filtered_df[\"long\"] = filtered_df[\"long\"].astype(str).str.replace(\",\", \".\")\n",
    "\n",
    "# Convertir les colonnes en type float pour une manipulation correcte (si nécessaire)\n",
    "filtered_df[\"lat\"] = filtered_df[\"lat\"].astype(float)\n",
    "filtered_df[\"long\"] = filtered_df[\"long\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Création de colonnes pour mesurer la qualité des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analyse des heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Num_Acc        date    an      mois      jour   hrmn dep    com  \\\n",
      "136    200500003397  2005-01-13  2005   janvier     jeudi   73:0  38  38185   \n",
      "137    200500003400  2005-01-14  2005   janvier  vendredi  17:45  38  38185   \n",
      "141    200500003415  2005-01-25  2005   janvier     mardi   90:5  38  38185   \n",
      "339    200500007846  2005-02-18  2005   février  vendredi  17:30  38  38185   \n",
      "637    200500015267  2005-03-30  2005      mars  mercredi  17:35  38  38185   \n",
      "...             ...         ...   ...       ...       ...    ...  ..    ...   \n",
      "60668  201700027686  2017-11-30  2017  novembre     jeudi  19:30  38  38185   \n",
      "60669  201700027686  2017-11-30  2017  novembre     jeudi  19:30  38  38185   \n",
      "64862  201800025689  2018-01-24  2018   janvier  mercredi  14:20  38  38185   \n",
      "66393  201900008440  2019-04-23  2019     avril     mardi  12:30  38  38185   \n",
      "67403  201900029141  2019-05-05  2019       mai  dimanche  17:10  38  38185   \n",
      "\n",
      "              lat       long  ...  equipement  obs  obsm  choc  manv  \\\n",
      "136           0.0        0.0  ...           9  0.0   2.0   8.0   1.0   \n",
      "137           0.0        0.0  ...           2  0.0   2.0   2.0   1.0   \n",
      "141           0.0        0.0  ...           9  0.0   2.0   1.0   1.0   \n",
      "339           0.0        0.0  ...           9  0.0   2.0   3.0  15.0   \n",
      "637           0.0        0.0  ...           4  0.0   2.0   1.0   1.0   \n",
      "...           ...        ...  ...         ...  ...   ...   ...   ...   \n",
      "60668    45.19057    5.71238  ...           9  0.0   1.0   1.0   1.0   \n",
      "60669    45.19057    5.71238  ...           8  0.0   1.0   1.0   1.0   \n",
      "64862    45.18542    5.73108  ...           2  0.0   2.0   1.0   1.0   \n",
      "66393  45,1886800  5,7150900  ...         NaN  0.0   1.0   1.0   1.0   \n",
      "67403  45,1733200  5,7421000  ...         NaN  0.0   0.0   8.0  19.0   \n",
      "\n",
      "            vehiculeid  typevehicules  manoeuvehicules  numVehicules  \\\n",
      "136    200500003397B01              7               15           1.0   \n",
      "137    200500003400B01              7               15           1.0   \n",
      "141    200500003415A01              7               15           1.0   \n",
      "339    200500007846A01              7                1           1.0   \n",
      "637    200500015267B01              7               16           1.0   \n",
      "...                ...            ...              ...           ...   \n",
      "60668  201700027686A01            NaN              NaN           NaN   \n",
      "60669  201700027686A01            NaN              NaN           NaN   \n",
      "64862  201800025689B01              7               16           1.0   \n",
      "66393  201900008440A01            NaN              NaN           NaN   \n",
      "67403  201900029141A01              7                1           1.0   \n",
      "\n",
      "        statut_heure  \n",
      "136    Non cohérente  \n",
      "137        Cohérente  \n",
      "141    Non cohérente  \n",
      "339        Cohérente  \n",
      "637        Cohérente  \n",
      "...              ...  \n",
      "60668      Cohérente  \n",
      "60669      Cohérente  \n",
      "64862      Cohérente  \n",
      "66393      Cohérente  \n",
      "67403      Cohérente  \n",
      "\n",
      "[337 rows x 40 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\281969821.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"statut_heure\"] = filtered_df[\"hrmn\"].astype(str).apply(verifier_heure)\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour vérifier si l'heure est cohérente\n",
    "def verifier_heure(heure):\n",
    "    try:\n",
    "        # Séparer l'heure et les minutes\n",
    "        h, m = map(int, heure.split(':'))\n",
    "        # Vérifier si l'heure et les minutes sont dans les plages valides\n",
    "        return \"Cohérente\" if 0 <= h <= 23 and 0 <= m <= 59 else \"Non cohérente\"\n",
    "    except:\n",
    "        return \"Non cohérente\"\n",
    "\n",
    "# Appliquer la fonction sur la colonne hrmn pour créer une nouvelle colonne statut_heure\n",
    "filtered_df[\"statut_heure\"] = filtered_df[\"hrmn\"].astype(str).apply(verifier_heure)\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analyse des coordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Num_Acc        date    an      mois      jour   hrmn dep    com  \\\n",
      "136    200500003397  2005-01-13  2005   janvier     jeudi   73:0  38  38185   \n",
      "137    200500003400  2005-01-14  2005   janvier  vendredi  17:45  38  38185   \n",
      "141    200500003415  2005-01-25  2005   janvier     mardi   90:5  38  38185   \n",
      "339    200500007846  2005-02-18  2005   février  vendredi  17:30  38  38185   \n",
      "637    200500015267  2005-03-30  2005      mars  mercredi  17:35  38  38185   \n",
      "...             ...         ...   ...       ...       ...    ...  ..    ...   \n",
      "60668  201700027686  2017-11-30  2017  novembre     jeudi  19:30  38  38185   \n",
      "60669  201700027686  2017-11-30  2017  novembre     jeudi  19:30  38  38185   \n",
      "64862  201800025689  2018-01-24  2018   janvier  mercredi  14:20  38  38185   \n",
      "66393  201900008440  2019-04-23  2019     avril     mardi  12:30  38  38185   \n",
      "67403  201900029141  2019-05-05  2019       mai  dimanche  17:10  38  38185   \n",
      "\n",
      "            lat     long  ...  obs  obsm  choc  manv       vehiculeid  \\\n",
      "136     0.00000  0.00000  ...  0.0   2.0   8.0   1.0  200500003397B01   \n",
      "137     0.00000  0.00000  ...  0.0   2.0   2.0   1.0  200500003400B01   \n",
      "141     0.00000  0.00000  ...  0.0   2.0   1.0   1.0  200500003415A01   \n",
      "339     0.00000  0.00000  ...  0.0   2.0   3.0  15.0  200500007846A01   \n",
      "637     0.00000  0.00000  ...  0.0   2.0   1.0   1.0  200500015267B01   \n",
      "...         ...      ...  ...  ...   ...   ...   ...              ...   \n",
      "60668  45.19057  5.71238  ...  0.0   1.0   1.0   1.0  201700027686A01   \n",
      "60669  45.19057  5.71238  ...  0.0   1.0   1.0   1.0  201700027686A01   \n",
      "64862  45.18542  5.73108  ...  0.0   2.0   1.0   1.0  201800025689B01   \n",
      "66393  45.18868  5.71509  ...  0.0   1.0   1.0   1.0  201900008440A01   \n",
      "67403  45.17332  5.74210  ...  0.0   0.0   8.0  19.0  201900029141A01   \n",
      "\n",
      "       typevehicules  manoeuvehicules  numVehicules   statut_heure  \\\n",
      "136                7               15           1.0  Non cohérente   \n",
      "137                7               15           1.0      Cohérente   \n",
      "141                7               15           1.0  Non cohérente   \n",
      "339                7                1           1.0      Cohérente   \n",
      "637                7               16           1.0      Cohérente   \n",
      "...              ...              ...           ...            ...   \n",
      "60668            NaN              NaN           NaN      Cohérente   \n",
      "60669            NaN              NaN           NaN      Cohérente   \n",
      "64862              7               16           1.0      Cohérente   \n",
      "66393            NaN              NaN           NaN      Cohérente   \n",
      "67403              7                1           1.0      Cohérente   \n",
      "\n",
      "         statut_coord  \n",
      "136    Non cohérentes  \n",
      "137    Non cohérentes  \n",
      "141    Non cohérentes  \n",
      "339    Non cohérentes  \n",
      "637    Non cohérentes  \n",
      "...               ...  \n",
      "60668      Cohérentes  \n",
      "60669      Cohérentes  \n",
      "64862      Cohérentes  \n",
      "66393      Cohérentes  \n",
      "67403      Cohérentes  \n",
      "\n",
      "[337 rows x 41 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\4172450745.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"statut_coord\"] = filtered_df.apply(lambda row: verifier_coord(row[\"lat\"], row[\"long\"]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour vérifier la cohérence des coordonnées\n",
    "def verifier_coord(lat, lon):\n",
    "    if lat == 0 or lon == 0:\n",
    "        return \"Non cohérentes\"\n",
    "    if lat < 45 or lat > 46:\n",
    "        return \"Non cohérentes\"\n",
    "    if lon < 5 or lon > 6:\n",
    "        return \"Non cohérentes\"\n",
    "    return \"Cohérentes\"\n",
    "\n",
    "# Appliquer la fonction ligne par ligne pour créer une nouvelle colonne\n",
    "filtered_df[\"statut_coord\"] = filtered_df.apply(lambda row: verifier_coord(row[\"lat\"], row[\"long\"]), axis=1)\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilisation des métadonnées pour remplacer les codes numériques par leur significations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"agg\"] = filtered_df[\"agg\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"int\"] = filtered_df[\"int\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"lum\"] = filtered_df[\"lum\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"atm\"] = filtered_df[\"atm\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"circ\"] = filtered_df[\"circ\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"prof\"] = filtered_df[\"prof\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"surf\"] = filtered_df[\"surf\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"situ\"] = filtered_df[\"situ\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"grav\"] = filtered_df[\"grav\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"sexe\"] = filtered_df[\"sexe\"].replace({\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_7060\\2167096452.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"trajet\"] = filtered_df[\"trajet\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# Pour agg\n",
    "filtered_df[\"agg\"] = filtered_df[\"agg\"].replace({\n",
    "    1: \"Hors agglomération\",\n",
    "    2: \"En agglomération\"\n",
    "})\n",
    "\n",
    "# Pour int\n",
    "filtered_df[\"int\"] = filtered_df[\"int\"].replace({\n",
    "    0: \"Non renseigné\",\n",
    "    1: \"Hors intersection\",\n",
    "    2: \"Intersection en X\",\n",
    "    3: \"Intersection en T\",\n",
    "    4: \"Intersection en Y\",\n",
    "    5: \"Intersection à plus de 4 branches\",\n",
    "    6: \"Giratoire\",\n",
    "    7: \"Place\",\n",
    "    8: \"Passage à niveau\",\n",
    "    9: \"Autre intersection\"\n",
    "})\n",
    "\n",
    "# Pour lum\n",
    "filtered_df[\"lum\"] = filtered_df[\"lum\"].replace({\n",
    "    1: \"Plein jour\",\n",
    "    2: \"Crépuscule ou aube\",\n",
    "    3: \"Nuit sans éclairage public\",\n",
    "    4: \"Nuit avec éclairage public non allumé\",\n",
    "    5: \"Nuit avec éclairage public allumé\"\n",
    "})\n",
    "\n",
    "# Pour atm\n",
    "filtered_df[\"atm\"] = filtered_df[\"atm\"].replace({\n",
    "    1: \"Normale\",\n",
    "    2: \"Pluie légère\",\n",
    "    3: \"Pluie forte\",\n",
    "    4: \"Neige - grêle\",\n",
    "    5: \"Brouillard - fumée\",\n",
    "    6: \"Vent fort - tempête\",\n",
    "    7: \"Temps éblouissant\",\n",
    "    8: \"Temps couvert\",\n",
    "    9: \"Autre\",\n",
    "    -1: \"Non renseigné\"\n",
    "})\n",
    "\n",
    "# Pour circ\n",
    "filtered_df[\"circ\"] = filtered_df[\"circ\"].replace({\n",
    "    1: \"A sens unique\",\n",
    "    2: \"Bidirectionnelle\",\n",
    "    3: \"A chaussées séparées\",\n",
    "    4: \"Avec voies d'affectation variable\",\n",
    "    -1: \"Non renseigné\"\n",
    "})\n",
    "\n",
    "# Pour prof\n",
    "filtered_df[\"prof\"] = filtered_df[\"prof\"].replace({\n",
    "    1: \"Plat\",\n",
    "    2: \"Pente\",\n",
    "    3: \"Sommet de côte\",\n",
    "    4: \"Bas de côte\",\n",
    "    -1: \"Non renseigné\"\n",
    "})\n",
    "\n",
    "# Pour surf\n",
    "filtered_df[\"surf\"] = filtered_df[\"surf\"].replace({\n",
    "    1: \"Normale\",\n",
    "    2: \"Mouillée\",\n",
    "    3: \"Flaques\",\n",
    "    4: \"Inondée\",\n",
    "    5: \"Enneigée\",\n",
    "    6: \"Boue\",\n",
    "    7: \"Verglacée\",\n",
    "    8: \"Corps gras - huile\",\n",
    "    9: \"Autre\",\n",
    "    -1: \"Non renseigné\"\n",
    "})\n",
    "\n",
    "# Pour situ\n",
    "filtered_df[\"situ\"] = filtered_df[\"situ\"].replace({\n",
    "    0: \"Aucun\",\n",
    "    1: \"Sur chaussée\",\n",
    "    2: \"Sur bande d'arrêt d'urgence\",\n",
    "    3: \"Sur accotement\",\n",
    "    4: \"Sur trottoir\",\n",
    "    5: \"Sur piste cyclable\",\n",
    "    6: \"Sur autre voie spéciale\",\n",
    "    8: \"Autres\",\n",
    "    -1: \"Non renseigné\"\n",
    "})\n",
    "\n",
    "# Pour grav\n",
    "filtered_df[\"grav\"] = filtered_df[\"grav\"].replace({\n",
    "    1: \"Indemne\",\n",
    "    2: \"Tué\",\n",
    "    3: \"Blessé hospitalisé\",\n",
    "    4: \"Blessé léger\"\n",
    "})\n",
    "\n",
    "# Pour sexe\n",
    "filtered_df[\"sexe\"] = filtered_df[\"sexe\"].replace({\n",
    "    1: \"Masculin\",\n",
    "    2: \"Féminin\"\n",
    "})\n",
    "\n",
    "# Pour trajet\n",
    "filtered_df[\"trajet\"] = filtered_df[\"trajet\"].replace({\n",
    "    0: \"Non renseigné\",\n",
    "    1: \"Domicile - travail\",\n",
    "    2: \"Domicile - école\",\n",
    "    3: \"Courses - achats\",\n",
    "    4: \"Utilisation professionnelle\",\n",
    "    5: \"Promenade - loisirs\",\n",
    "    9: \"Autre\",\n",
    "    -1: \"Non renseigné\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136                    Autre\n",
      "137                    Autre\n",
      "141            Non renseigné\n",
      "339      Promenade - loisirs\n",
      "637      Promenade - loisirs\n",
      "                ...         \n",
      "60668     Domicile - travail\n",
      "60669    Promenade - loisirs\n",
      "64862     Domicile - travail\n",
      "66393          Non renseigné\n",
      "67403    Promenade - loisirs\n",
      "Name: trajet, Length: 337, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df[\"trajet\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
